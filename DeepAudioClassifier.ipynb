{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErItPkMbJ4Hp"
      },
      "source": [
        "# 1. Import and Install Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTwPjMBlJ4Hr"
      },
      "source": [
        "## 1.1 Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfAN9TYyJ4Hr",
        "outputId": "adbfd61e-697e-4168-f3e5-d434a5889eca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.13.0\n",
            "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-gpu==2.13.0 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.12.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow-gpu==2.13.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.13.0 tensorflow-gpu==2.13.0 tensorflow-io==0.31.0 matplotlib==3.7.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJTr2kPlJ4Hs"
      },
      "source": [
        "## 1.2 Load Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "rBoPUK7TJ4Ht",
        "outputId": "f369f0e3-ee5a-411d-ddaa-91abffda705d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow_io'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-24f3ca54d50b>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_io\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_io'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nOaEb0jJ4Ht"
      },
      "source": [
        "# 2. Build Data Loading Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_F9i4caJ4Ht"
      },
      "source": [
        "## 2.1 Define Paths to Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "roz7jId5J4Hu"
      },
      "outputs": [],
      "source": [
        "CAPUCHIN_FILE = os.path.join('data', 'Parsed_Capuchinbird_Clips', 'XC3776-3.wav')\n",
        "NOT_CAPUCHIN_FILE = os.path.join('data', 'Parsed_Not_Capuchinbird_Clips', 'afternoon-birds-song-in-forest-0.wav')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSi_6AiqJ4Hu"
      },
      "source": [
        "## 2.2 Build Dataloading Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "KfSaWgU5J4Hu"
      },
      "outputs": [],
      "source": [
        "def load_wav_16k_mono(filename):\n",
        "    # Load encoded wav file\n",
        "    file_contents = tf.io.read_file(filename)\n",
        "    # Decode wav (tensors by channels)\n",
        "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
        "    # Removes trailing axis\n",
        "    wav = tf.squeeze(wav, axis=-1)\n",
        "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
        "    # Goes from 44100Hz to 16000hz - amplitude of the audio signal\n",
        "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
        "    return wav"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISyoIfzxJ4Hv"
      },
      "source": [
        "## 2.3 Plot Wave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "PfrsSXABJ4Hv"
      },
      "outputs": [],
      "source": [
        "wave = load_wav_16k_mono(CAPUCHIN_FILE)\n",
        "nwave = load_wav_16k_mono(NOT_CAPUCHIN_FILE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "_DcE2ksgJ4Hv"
      },
      "outputs": [],
      "source": [
        "plt.plot(wave)\n",
        "plt.plot(nwave)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBVvR3NqJ4Hw"
      },
      "source": [
        "# 3. Create Tensorflow Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaMR8GRQJ4Hw"
      },
      "source": [
        "## 3.1 Define Paths to Positive and Negative Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "u43oexcuJ4Hw"
      },
      "outputs": [],
      "source": [
        "POS = os.path.join('data', 'Parsed_Capuchinbird_Clips')\n",
        "NEG = os.path.join('data', 'Parsed_Not_Capuchinbird_Clips')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWXK9LjCJ4Hw"
      },
      "source": [
        "## 3.2 Create Tensorflow Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "2j_tZsJxJ4Hw"
      },
      "outputs": [],
      "source": [
        "pos = tf.data.Dataset.list_files(POS+'\\*.wav')\n",
        "neg = tf.data.Dataset.list_files(NEG+'\\*.wav')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufzHSQHbJ4Hw"
      },
      "source": [
        "## 3.3 Add labels and Combine Positive and Negative Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "Yt28GU70J4Hw"
      },
      "outputs": [],
      "source": [
        "positives = tf.data.Dataset.zip((pos, tf.data.Dataset.from_tensor_slices(tf.ones(len(pos)))))\n",
        "negatives = tf.data.Dataset.zip((neg, tf.data.Dataset.from_tensor_slices(tf.zeros(len(neg)))))\n",
        "data = positives.concatenate(negatives)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XFWAxTzJ4Hx"
      },
      "source": [
        "# 4. Determine Average Length of a Capuchin Call"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDsC_iZgJ4Hx"
      },
      "source": [
        "## 4.1 Calculate Wave Cycle Length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "0ng9CuHFJ4Hx"
      },
      "outputs": [],
      "source": [
        "lengths = []\n",
        "for file in os.listdir(os.path.join('data', 'Parsed_Capuchinbird_Clips')):\n",
        "    tensor_wave = load_wav_16k_mono(os.path.join('data', 'Parsed_Capuchinbird_Clips', file))\n",
        "    lengths.append(len(tensor_wave))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFO3fLQbJ4Hx"
      },
      "source": [
        "## 4.2 Calculate Mean, Min and Max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "M1wBiNwJJ4Hx"
      },
      "outputs": [],
      "source": [
        "tf.math.reduce_mean(lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "nmtZb2aaJ4Hx"
      },
      "outputs": [],
      "source": [
        "tf.math.reduce_min(lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "FEgVIWRKJ4Hy"
      },
      "outputs": [],
      "source": [
        "tf.math.reduce_max(lengths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z85TZJ6YJ4Hy"
      },
      "source": [
        "# 5. Build Preprocessing Function to Convert to Spectrogram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEBkW5bsJ4Hy"
      },
      "source": [
        "## 5.1 Build Preprocessing Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "zyGTACXaJ4Hy"
      },
      "outputs": [],
      "source": [
        "def preprocess(file_path, label):\n",
        "    wav = load_wav_16k_mono(file_path)\n",
        "    wav = wav[:48000]\n",
        "    zero_padding = tf.zeros([48000] - tf.shape(wav), dtype=tf.float32)\n",
        "    wav = tf.concat([zero_padding, wav],0)\n",
        "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
        "    spectrogram = tf.abs(spectrogram)\n",
        "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
        "    return spectrogram, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9a4pR1yJ4Hy"
      },
      "source": [
        "## 5.2 Test Out the Function and Viz the Spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "6Tx6UwroJ4Hy"
      },
      "outputs": [],
      "source": [
        "filepath, label = positives.shuffle(buffer_size=10000).as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "pLhsjx4TJ4Hz"
      },
      "outputs": [],
      "source": [
        "spectrogram, label = preprocess(filepath, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "aj1txARGJ4Hz"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(30,20))\n",
        "plt.imshow(tf.transpose(spectrogram)[0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD9PNw40J4Hz"
      },
      "source": [
        "# 6. Create Training and Testing Partitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp64yvXsJ4Hz"
      },
      "source": [
        "## 6.1 Create a Tensorflow Data Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "SaFZl8kIJ4Hz"
      },
      "outputs": [],
      "source": [
        "data = data.map(preprocess)\n",
        "data = data.cache()\n",
        "data = data.shuffle(buffer_size=1000)\n",
        "data = data.batch(16)\n",
        "data = data.prefetch(8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcgLLCtJJ4H0"
      },
      "source": [
        "## 6.2 Split into Training and Testing Partitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "uDB4dShxJ4H0"
      },
      "outputs": [],
      "source": [
        "train = data.take(36)\n",
        "test = data.skip(36).take(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Tz9u-PLJ4H-"
      },
      "source": [
        "## 6.3 Test One Batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "dtz0IOM0J4H-"
      },
      "outputs": [],
      "source": [
        "samples, labels = train.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "5eBHiXxwJ4H-"
      },
      "outputs": [],
      "source": [
        "samples.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0LZMRj7J4H_"
      },
      "source": [
        "# 7. Build Deep Learning Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDPaXaAwJ4H_"
      },
      "source": [
        "## 7.1 Load Tensorflow Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "I46woI8WJ4H_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuC6z2cfJ4H_"
      },
      "source": [
        "## 7.2 Build Sequential Model, Compile and View Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "mzX8tOCOJ4H_"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3,3), activation='relu', input_shape=(1491, 257,1)))\n",
        "model.add(Conv2D(16, (3,3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "s4C3R2LLJ4IA"
      },
      "outputs": [],
      "source": [
        "model.compile('Adam', loss='BinaryCrossentropy', metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "yH93cbGhJ4IA"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40nDI9NuJ4IA"
      },
      "source": [
        "## 7.3 Fit Model, View Loss and KPI Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "-iViXe53J4IA"
      },
      "outputs": [],
      "source": [
        "hist = model.fit(train, epochs=4, validation_data=test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "TQocq7aRJ4IA"
      },
      "outputs": [],
      "source": [
        "plt.title('Loss')\n",
        "plt.plot(hist.history['loss'], 'r')\n",
        "plt.plot(hist.history['val_loss'], 'b')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "h6fvELh8J4IA"
      },
      "outputs": [],
      "source": [
        "plt.title('Precision')\n",
        "plt.plot(hist.history['precision'], 'r')\n",
        "plt.plot(hist.history['val_precision'], 'b')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "CTSDG7geJ4IB"
      },
      "outputs": [],
      "source": [
        "plt.title('Recall')\n",
        "plt.plot(hist.history['recall'], 'r')\n",
        "plt.plot(hist.history['val_recall'], 'b')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YO1V8MR3J4IB"
      },
      "source": [
        "# 8. Make a Prediction on a Single Clip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvxQDhQVJ4IB"
      },
      "source": [
        "## 8.1 Get One Batch and Make a Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "Dqi_7_eyJ4IB"
      },
      "outputs": [],
      "source": [
        "X_test, y_test = test.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "8dawjcSfJ4IC"
      },
      "outputs": [],
      "source": [
        "yhat = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38rfUYa4J4IC"
      },
      "source": [
        "## 8.2 Convert Logits to Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "9K9vWez2J4IC"
      },
      "outputs": [],
      "source": [
        "yhat = [1 if prediction > 0.5 else 0 for prediction in yhat]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "CV1dRqqpJ4IC"
      },
      "source": [
        "# 9. Build Forest Parsing Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj2RYr1cJ4ID"
      },
      "source": [
        "## 9.1 Load up MP3s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "mMgKSGUkJ4ID"
      },
      "outputs": [],
      "source": [
        "def load_mp3_16k_mono(filename):\n",
        "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
        "    res = tfio.audio.AudioIOTensor(filename)\n",
        "    # Convert to tensor and combine channels\n",
        "    tensor = res.to_tensor()\n",
        "    tensor = tf.math.reduce_sum(tensor, axis=1) / 2\n",
        "    # Extract sample rate and cast\n",
        "    sample_rate = res.rate\n",
        "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
        "    # Resample to 16 kHz\n",
        "    wav = tfio.audio.resample(tensor, rate_in=sample_rate, rate_out=16000)\n",
        "    return wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "Eq0E_qoiJ4ID"
      },
      "outputs": [],
      "source": [
        "mp3 = os.path.join('data', 'Forest Recordings', 'recording_00.mp3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "9LflpECpJ4ID"
      },
      "outputs": [],
      "source": [
        "wav = load_mp3_16k_mono(mp3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "THUE2i_lJ4IE"
      },
      "outputs": [],
      "source": [
        "audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "_oIaloFFJ4IE"
      },
      "outputs": [],
      "source": [
        "samples, index = audio_slices.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3f-CGS9J4IE"
      },
      "source": [
        "## 9.2 Build Function to Convert Clips into Windowed Spectrograms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "Aq47aKuhJ4IE"
      },
      "outputs": [],
      "source": [
        "def preprocess_mp3(sample, index):\n",
        "    sample = sample[0]\n",
        "    zero_padding = tf.zeros([48000] - tf.shape(sample), dtype=tf.float32)\n",
        "    wav = tf.concat([zero_padding, sample],0)\n",
        "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
        "    spectrogram = tf.abs(spectrogram)\n",
        "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
        "    return spectrogram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqcYAKo5J4IE"
      },
      "source": [
        "## 9.3 Convert Longer Clips into Windows and Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "UQh7CB7bJ4IF"
      },
      "outputs": [],
      "source": [
        "audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=16000, sequence_stride=16000, batch_size=1)\n",
        "audio_slices = audio_slices.map(preprocess_mp3)\n",
        "audio_slices = audio_slices.batch(64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "BoJLPy3PJ4IF"
      },
      "outputs": [],
      "source": [
        "yhat = model.predict(audio_slices)\n",
        "yhat = [1 if prediction > 0.5 else 0 for prediction in yhat]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a5P7eJWJ4IF"
      },
      "source": [
        "## 9.4 Group Consecutive Detections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "_UIvze9tJ4IF"
      },
      "outputs": [],
      "source": [
        "from itertools import groupby"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "JrrkqMIbJ4IF"
      },
      "outputs": [],
      "source": [
        "yhat = [key for key, group in groupby(yhat)]\n",
        "calls = tf.math.reduce_sum(yhat).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "bRCpSJcMJ4IF"
      },
      "outputs": [],
      "source": [
        "calls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwVs_rJdJ4IG"
      },
      "source": [
        "# 10. Make Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEsG580QJ4IG"
      },
      "source": [
        "## 10.1 Loop over all recordings and make predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "uRH-EkfrJ4IG"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "for file in os.listdir(os.path.join('data', 'Forest Recordings')):\n",
        "    FILEPATH = os.path.join('data','Forest Recordings', file)\n",
        "\n",
        "    wav = load_mp3_16k_mono(FILEPATH)\n",
        "    audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)\n",
        "    audio_slices = audio_slices.map(preprocess_mp3)\n",
        "    audio_slices = audio_slices.batch(64)\n",
        "\n",
        "    yhat = model.predict(audio_slices)\n",
        "\n",
        "    results[file] = yhat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "scrolled": true,
        "tags": [],
        "id": "tGTyjamoJ4IG"
      },
      "outputs": [],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS7tYu3RJ4IG"
      },
      "source": [
        "## 10.2 Convert Predictions into Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "scrolled": true,
        "tags": [],
        "id": "UAJmubvQJ4IH"
      },
      "outputs": [],
      "source": [
        "class_preds = {}\n",
        "for file, logits in results.items():\n",
        "    class_preds[file] = [1 if prediction > 0.99 else 0 for prediction in logits]\n",
        "class_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaUK8rOfJ4IH"
      },
      "source": [
        "## 10.3 Group Consecutive Detections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "scrolled": true,
        "tags": [],
        "id": "deyWFyq7J4IH"
      },
      "outputs": [],
      "source": [
        "postprocessed = {}\n",
        "for file, scores in class_preds.items():\n",
        "    postprocessed[file] = tf.math.reduce_sum([key for key, group in groupby(scores)]).numpy()\n",
        "postprocessed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9UxRp2HJ4IH"
      },
      "source": [
        "# 11. Export Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "-2j1XMSuJ4II"
      },
      "outputs": [],
      "source": [
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "aNklXfpFJ4II"
      },
      "outputs": [],
      "source": [
        "with open('results.csv', 'w', newline='') as f:\n",
        "    writer = csv.writer(f, delimiter=',')\n",
        "    writer.writerow(['recording', 'capuchin_calls'])\n",
        "    for key, value in postprocessed.items():\n",
        "        writer.writerow([key, value])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "audioc",
      "language": "python",
      "name": "audioc"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}